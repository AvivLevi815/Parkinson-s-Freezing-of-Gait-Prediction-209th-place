{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e028530",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:44.879654Z",
     "iopub.status.busy": "2023-05-25T15:30:44.878826Z",
     "iopub.status.idle": "2023-05-25T15:30:48.682395Z",
     "shell.execute_reply": "2023-05-25T15:30:48.680847Z"
    },
    "papermill": {
     "duration": 3.817304,
     "end_time": "2023-05-25T15:30:48.685794",
     "exception": false,
     "start_time": "2023-05-25T15:30:44.868490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca1c08c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:48.702498Z",
     "iopub.status.busy": "2023-05-25T15:30:48.702005Z",
     "iopub.status.idle": "2023-05-25T15:30:48.725705Z",
     "shell.execute_reply": "2023-05-25T15:30:48.723695Z"
    },
    "papermill": {
     "duration": 0.03596,
     "end_time": "2023-05-25T15:30:48.729171",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.693211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "black_list = pickle.load(open(\"/kaggle/input/black-list-v8-1/black_list.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecae1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:48.746672Z",
     "iopub.status.busy": "2023-05-25T15:30:48.745727Z",
     "iopub.status.idle": "2023-05-25T15:30:48.842707Z",
     "shell.execute_reply": "2023-05-25T15:30:48.841065Z"
    },
    "papermill": {
     "duration": 0.109894,
     "end_time": "2023-05-25T15:30:48.846204",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.736310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "defog_metadata = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/defog_metadata.csv\")\n",
    "\n",
    "subjects = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/subjects.csv\")\n",
    "subjects[\"Visit\"] = subjects[\"Visit\"].fillna(1)\n",
    "subjects = subjects.drop_duplicates(subset=[\"Subject\", \"Visit\"])\n",
    "\n",
    "defog_metadata[\"Medication\"] = np.where(defog_metadata[\"Medication\"] == \"on\", 1, 0)\n",
    "defog_subject_dict = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Subject\"]))\n",
    "defog_medication_dict = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Medication\"]))\n",
    "defog_Id_Visit = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Visit\"]))\n",
    "defog_Id_Test  =dict(zip(defog_metadata[\"Id\"], np.zeros(defog_metadata.shape[0])))\n",
    "\n",
    "subjects[\"UPDRSIII_On\"] = subjects[\"UPDRSIII_On\"].fillna(0)\n",
    "subjects[\"UPDRSIII_Off\"] = subjects[\"UPDRSIII_Off\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c1a514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:48.863061Z",
     "iopub.status.busy": "2023-05-25T15:30:48.862567Z",
     "iopub.status.idle": "2023-05-25T15:30:48.891300Z",
     "shell.execute_reply": "2023-05-25T15:30:48.889859Z"
    },
    "papermill": {
     "duration": 0.040635,
     "end_time": "2023-05-25T15:30:48.894266",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.853631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe_max_min(df, ranges_maxs):\n",
    "    new_cols = []\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        past_1 = df[col].shift(1).fillna(method=\"bfill\")\n",
    "        future_1 = df[col].shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "        is_max = np.where((df[col] > past_1) & (df[col] > future_1), True, False)\n",
    "        is_min = np.where((df[col] < past_1) & (df[col] < future_1), True, False)\n",
    "\n",
    "        last_max_temp = df[col].where(is_max).ffill().fillna(0)\n",
    "        last_min_temp = df[col].where(is_min).ffill().fillna(0)\n",
    "\n",
    "        maxs_df = pd.DataFrame(df[col].where(is_max).dropna())\n",
    "        maxs_df['Time'] = df[\"Time\"].where(is_max).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_max_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_max_{lag}_ago\")\n",
    "                    maxs_df[f\"{col}_max_{lag}_ago\"] = maxs_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].std(axis=1)\n",
    "\n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_maxs\", \n",
    "                            f\"{col}_max_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_mean_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_std_past_{lags_max}_maxs\"])\n",
    "\n",
    "\n",
    "        mins_df = pd.DataFrame(df[col].where(is_min).dropna())\n",
    "        mins_df['Time'] = df[\"Time\"].where(is_min).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_min_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_min_{lag}_ago\")\n",
    "                    mins_df[f\"{col}_min_{lag}_ago\"] = mins_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_mins\"] = mins_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_mins\"] = mins_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_mins\"] = mins_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_mins\"] = mins_df[cols_to_stat].std(axis=1)\n",
    "    \n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_mins\", \n",
    "                f\"{col}_max_past_{lags_max}_mins\",\n",
    "                f\"{col}_mean_past_{lags_max}_mins\",\n",
    "                f\"{col}_std_past_{lags_max}_mins\"])\n",
    "    for col in new_cols:\n",
    "        df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    del mins_df, maxs_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a92399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:48.911037Z",
     "iopub.status.busy": "2023-05-25T15:30:48.910258Z",
     "iopub.status.idle": "2023-05-25T15:30:48.953067Z",
     "shell.execute_reply": "2023-05-25T15:30:48.951666Z"
    },
    "papermill": {
     "duration": 0.055162,
     "end_time": "2023-05-25T15:30:48.956497",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.901335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lag_feature(df,col_to_lag, lag, second,lag_scale=\"Time\" ):\n",
    "    if lag_scale == \"Time\":\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[col_to_lag].shift(lag*second).fillna(method=\"bfill\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[col_to_lag].shift(-lag*second).fillna(method=\"ffill\")\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].fillna(0)\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].fillna(0)\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].astype(\"float32\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].astype(\"float32\")\n",
    "                                                                                                               \n",
    "    return df\n",
    "\n",
    "def min_max_feature(df, feature):\n",
    "    new_feature = f\"precent_prograss_{feature}\"\n",
    "    df[new_feature] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())\n",
    "    df[new_feature] = df[new_feature].astype(\"float16\")                                                                                                           \n",
    "    return df\n",
    "\n",
    "def fix_invalid_events(df):\n",
    "    for e_type in [\"StartHesitation\", \"Turn\",'Walking']:\n",
    "        df.loc[(df[\"Valid\"] == False) | (df[\"Task\"] == False), e_type] = 0\n",
    "        \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "- Stats in fences, for example, 2 seconds ago - 4 seconds ago,\n",
    "what was the mean? std? max? min?\n",
    "\"\"\"\n",
    "def fences_features(df,col, margin, width, stat, second):\n",
    "    stat_feature = f\"moving_{stat}_{col}_{width}\"\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[stat_feature].shift(margin*second).fillna(method=\"bfill\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[stat_feature].shift(-margin*second).fillna(method=\"ffill\")\n",
    "    \n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[f\"fence_{col}_m{margin}_w{width}_past\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[f\"fence_{col}_m{margin}_w{width}_future\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"]= df[f\"fence_{col}_m{margin}_w{width}_future\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"]= df[f\"fence_{col}_m{margin}_w{width}_past\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# def whole file stats - std/min/max/precentiles\n",
    "def whole_file_stats(df):\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        df[f\"graph_{col}_mean\"] = df[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_{col}_std\"] = df[col].std().astype(\"float16\")\n",
    "        df[f\"graph_{col}_min\"] = df[col].min().astype(\"float16\")\n",
    "        df[f\"graph_{col}_max\"] = df[col].max().astype(\"float16\")\n",
    "        \n",
    "        half_file = df.shape[0] // 2\n",
    "        \n",
    "        first_half = df.iloc[:half_file]\n",
    "        second_half = df.iloc[half_file:]\n",
    "        \n",
    "        df[f\"graph_first_half_{col}_mean\"] = first_half[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_std\"] = first_half[col].std().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_min\"] = first_half[col].min().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_max\"] = first_half[col].max().astype(\"float16\")\n",
    "        \n",
    "        df[f\"graph_second_half_{col}_mean\"] = second_half[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_std\"] = second_half[col].std().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_min\"] = second_half[col].min().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_max\"] = second_half[col].max().astype(\"float16\")\n",
    "    return df\n",
    "        \n",
    "def FE(df, is_td, isTest=False ):\n",
    "#     tdcsfog (128 timesteps per second)\n",
    "#     defog (100 timesteps per second).\n",
    "\n",
    "    df = describe_max_min(df, [10,20, 30, 40])\n",
    "    df = whole_file_stats(df)\n",
    "    if is_td:\n",
    "        second = 128\n",
    "    else:\n",
    "        second = 100\n",
    "\n",
    "    \n",
    "    if not isTest:\n",
    "        if \"Valid\" in df.columns:\n",
    "            df = fix_invalid_events(df)\n",
    "                                                                                                               \n",
    "    for col in [\"Time\", \"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        df = min_max_feature(df, col)\n",
    "    \n",
    "    \n",
    "    for col in [\"AccV\", \"AccAP\"]:\n",
    "        new_col = col + \"_pct\"\n",
    "        df[new_col] = df[col].pct_change()\n",
    "        df[new_col] = df[new_col].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\")\n",
    "        df[new_col] = df[new_col].fillna(0).astype(\"float32\") # 0 to 0 returns null\n",
    "       \n",
    "                        \n",
    "        for margin in [5,10, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105]:\n",
    "            for w in[5,10]:\n",
    "                real_winow= second * w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[new_col].rolling(window = real_winow).std().fillna(method=\"bfill\")\n",
    "                # in case the file is smaller than w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[f\"moving_std_{new_col}_{w}\"].fillna(-1)\n",
    "                df = fences_features(df,new_col, margin=margin, width=w, stat=\"std\", second=second)\n",
    "                df[f\"moving_std_{new_col}_{w}\"] =  df[f\"moving_std_{new_col}_{w}\"].astype(\"float32\")\n",
    "        \n",
    "        df[f\"moving_std_all_{col}\"] = df[col].expanding().std().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_std_all_{col}\")\n",
    "        \n",
    "        df[f\"moving_mean_all_{col}\"] = df[col].expanding().mean().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_mean_all_{col}\")\n",
    "\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b029a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:48.974444Z",
     "iopub.status.busy": "2023-05-25T15:30:48.973983Z",
     "iopub.status.idle": "2023-05-25T15:30:48.983236Z",
     "shell.execute_reply": "2023-05-25T15:30:48.981662Z"
    },
    "papermill": {
     "duration": 0.021987,
     "end_time": "2023-05-25T15:30:48.986174",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.964187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target\n",
    "def create_target(df):\n",
    "    class_dict = {0: \"StartHesitation\", 1: \"Turn\", 2:\"Walking\", 3:\"None\"}\n",
    "    df[\"target\"] = 3\n",
    "    df[\"target\"] = np.where(df[\"StartHesitation\"] == 1, 0, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Turn\"] == 1, 1, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Walking\"] == 1, 2, df[\"target\"] )\n",
    "    \n",
    "    df = df.drop([\"StartHesitation\", \"Turn\", \"Walking\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df38da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.002846Z",
     "iopub.status.busy": "2023-05-25T15:30:49.001859Z",
     "iopub.status.idle": "2023-05-25T15:30:49.012398Z",
     "shell.execute_reply": "2023-05-25T15:30:49.010940Z"
    },
    "papermill": {
     "duration": 0.022236,
     "end_time": "2023-05-25T15:30:49.015557",
     "exception": false,
     "start_time": "2023-05-25T15:30:48.993321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def down_sample_stf(df, n_splits):   \n",
    "    print(f\"before split df has: {df.shape[0]} rows, {df.Subject.nunique()} people\")\n",
    "    n_rows_init = df.shape[0]\n",
    "    n_subjects_init = df.Subject.nunique()\n",
    "    X = df.drop(\"target\", axis = 1)\n",
    "    y = df[\"target\"]\n",
    "    groups = df[\"Subject\"]\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):\n",
    "        train = df.loc[train_index]\n",
    "        valid = df.loc[test_index]\n",
    "        break\n",
    "        \n",
    "    print(f\"after split train has: {train.shape[0]} rows and {train.Subject.nunique()} people\")\n",
    "    print(f\"valid has:{valid.shape[0]} rows and {valid.Subject.nunique()} people\")\n",
    "\n",
    "    return train, valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aea8d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.032649Z",
     "iopub.status.busy": "2023-05-25T15:30:49.031227Z",
     "iopub.status.idle": "2023-05-25T15:30:49.038188Z",
     "shell.execute_reply": "2023-05-25T15:30:49.037017Z"
    },
    "papermill": {
     "duration": 0.018567,
     "end_time": "2023-05-25T15:30:49.041007",
     "exception": false,
     "start_time": "2023-05-25T15:30:49.022440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_dtypes(df):\n",
    "    df[\"StartHesitation\"] = df[\"StartHesitation\"].astype(\"bool\")\n",
    "    df[\"Turn\"] = df[\"Turn\"].dfstype(\"bool\")\n",
    "    df[\"Walking\"] = df[\"Walking\"].astype(\"bool\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c5bca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.058021Z",
     "iopub.status.busy": "2023-05-25T15:30:49.056789Z",
     "iopub.status.idle": "2023-05-25T15:30:49.065798Z",
     "shell.execute_reply": "2023-05-25T15:30:49.064191Z"
    },
    "papermill": {
     "duration": 0.020775,
     "end_time": "2023-05-25T15:30:49.068986",
     "exception": false,
     "start_time": "2023-05-25T15:30:49.048211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_outliers(df):\n",
    "    for col in ['AccV','AccML','AccV']:\n",
    "        max_value = df[col].quantile(q=0.99)\n",
    "        min_value = df[col].quantile(q=0.01)\n",
    "        df[col] = np.where(df[col] > max_value, max_value, df[col])\n",
    "        df[col] = np.where(df[col] < min_value, min_value, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369e973c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.086978Z",
     "iopub.status.busy": "2023-05-25T15:30:49.085587Z",
     "iopub.status.idle": "2023-05-25T15:30:49.103518Z",
     "shell.execute_reply": "2023-05-25T15:30:49.102411Z"
    },
    "papermill": {
     "duration": 0.02987,
     "end_time": "2023-05-25T15:30:49.106586",
     "exception": false,
     "start_time": "2023-05-25T15:30:49.076716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
    "            if (col_type != 'object'):\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
    "    \n",
    "    return df\n",
    "#reference: https://www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1018f4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.123600Z",
     "iopub.status.busy": "2023-05-25T15:30:49.123149Z",
     "iopub.status.idle": "2023-05-25T15:30:49.139216Z",
     "shell.execute_reply": "2023-05-25T15:30:49.137725Z"
    },
    "papermill": {
     "duration": 0.028183,
     "end_time": "2023-05-25T15:30:49.142134",
     "exception": false,
     "start_time": "2023-05-25T15:30:49.113951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(base,isTest=False, black_list = []):\n",
    "    train= pd.DataFrame()\n",
    "    if \"tdcsfog\" in base:\n",
    "        is_td = True\n",
    "    else:\n",
    "        is_td = False\n",
    "        \n",
    "    for train_path in tqdm(os.listdir(base)):\n",
    "        file_path = base + '/'+train_path\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = flat_outliers(df)\n",
    "        df = FE(df, is_td)\n",
    "        if not isTest:\n",
    "            df = create_target(df)\n",
    "        df[\"file\"] = train_path.split(\".\")[0]\n",
    "        df[\"id\"] = df[\"file\"].astype(\"str\") + \"_\" + df[\"Time\"].astype(\"str\")\n",
    "\n",
    "        dot_index = train_path.index(\".\")\n",
    "        file_id = train_path[:dot_index]\n",
    "\n",
    "        if \"tdcsfog\" in base:\n",
    "            df[\"Subject\"] = tdcsfog_subject_dict[file_id]\n",
    "            df[\"Medication\"] =  tdcsfog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = tdcsfog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =tdcsfog_Id_Test[file_id]\n",
    "\n",
    "        else:\n",
    "            df[\"Subject\"] = defog_subject_dict[file_id]\n",
    "            df[\"Medication\"] = defog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = defog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =defog_Id_Test[file_id]\n",
    "\n",
    "        if train.shape[0] == 0:\n",
    "            cur_black_list = [c for c in black_list if c in df.columns]\n",
    "        train = train.append(df.drop(cur_black_list, axis = 1))\n",
    "        del df\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    train = reduce_memory_usage(train)\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a8d0cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:30:49.159513Z",
     "iopub.status.busy": "2023-05-25T15:30:49.158976Z",
     "iopub.status.idle": "2023-05-25T15:44:50.481766Z",
     "shell.execute_reply": "2023-05-25T15:44:50.480173Z"
    },
    "papermill": {
     "duration": 841.353366,
     "end_time": "2023-05-25T15:44:50.502622",
     "exception": false,
     "start_time": "2023-05-25T15:30:49.149256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/91 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:88: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "100%|██████████| 91/91 [10:19<00:00,  6.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 10267.70 MB\n",
      "Memory usage became:  4179.352600097656  MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defog_train = make_df(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog\", black_list=black_list)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626d0b5",
   "metadata": {
    "papermill": {
     "duration": 0.016016,
     "end_time": "2023-05-25T15:44:50.534854",
     "exception": false,
     "start_time": "2023-05-25T15:44:50.518838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb7fefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:44:50.571517Z",
     "iopub.status.busy": "2023-05-25T15:44:50.571046Z",
     "iopub.status.idle": "2023-05-25T15:46:36.407629Z",
     "shell.execute_reply": "2023-05-25T15:46:36.406131Z"
    },
    "papermill": {
     "duration": 105.858938,
     "end_time": "2023-05-25T15:46:36.410886",
     "exception": false,
     "start_time": "2023-05-25T15:44:50.551948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before split df has: 13525702 rows, 38 people\n",
      "after split train has: 10136077 rows and 28 people\n",
      "valid has:3389625 rows and 10 people\n",
      "(10136077, 126)\n",
      "(3389625, 126)\n",
      "(10136077, 132)\n",
      "(3389625, 132)\n",
      "train nans: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = down_sample_stf(defog_train, 4)\n",
    "del defog_train\n",
    "gc.collect()\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "\n",
    "# merging only on Subject because Visit is relevant for defog only\n",
    "train = train.merge(subjects, on=[\"Subject\",\"Visit\"], how=\"left\")\n",
    "train['Sex'] = np.where(train['Sex'] == \"M\", 1, 0)\n",
    "\n",
    "valid = valid.merge(subjects, on=[\"Subject\",\"Visit\"], how=\"left\")\n",
    "valid['Sex'] = np.where(valid['Sex'] == \"M\", 1, 0)\n",
    "\n",
    "del subjects\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "\n",
    "print(f\"train nans: {train.isna().sum().sum()}\")\n",
    "isn = train.isna().sum()\n",
    "isn[isn > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afabdf9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:46:36.448042Z",
     "iopub.status.busy": "2023-05-25T15:46:36.446405Z",
     "iopub.status.idle": "2023-05-25T15:46:39.947993Z",
     "shell.execute_reply": "2023-05-25T15:46:39.946482Z"
    },
    "papermill": {
     "duration": 3.523031,
     "end_time": "2023-05-25T15:46:39.951012",
     "exception": false,
     "start_time": "2023-05-25T15:46:36.427981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid nans: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"valid nans: {valid.isna().sum().sum()}\")\n",
    "isn = valid.isna().sum()\n",
    "isn[isn > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dab5e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:46:39.987472Z",
     "iopub.status.busy": "2023-05-25T15:46:39.986991Z",
     "iopub.status.idle": "2023-05-25T15:47:25.246441Z",
     "shell.execute_reply": "2023-05-25T15:47:25.244519Z"
    },
    "papermill": {
     "duration": 45.281865,
     "end_time": "2023-05-25T15:47:25.250234",
     "exception": false,
     "start_time": "2023-05-25T15:46:39.968369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 3818.81 MB\n",
      "Memory usage became:  3374.1540384292603  MB\n",
      "Memory usage of dataframe is 1689.19 MB\n",
      "Memory usage became:  1488.76496219635  MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = reduce_memory_usage(train)\n",
    "valid = reduce_memory_usage(valid)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76508d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:47:25.298002Z",
     "iopub.status.busy": "2023-05-25T15:47:25.297408Z",
     "iopub.status.idle": "2023-05-25T15:47:56.986392Z",
     "shell.execute_reply": "2023-05-25T15:47:56.984721Z"
    },
    "papermill": {
     "duration": 31.718419,
     "end_time": "2023-05-25T15:47:56.989863",
     "exception": false,
     "start_time": "2023-05-25T15:47:25.271444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(train.reset_index(drop=True), open(\"train_de.pkl\", \"wb\"))\n",
    "pickle.dump(valid.reset_index(drop=True), open(\"valid_de.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1049.947644,
   "end_time": "2023-05-25T15:47:58.945989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-25T15:30:28.998345",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
