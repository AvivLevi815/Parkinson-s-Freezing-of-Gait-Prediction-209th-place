{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece41c8f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-30T13:33:32.252244Z",
     "iopub.status.busy": "2023-05-30T13:33:32.251339Z",
     "iopub.status.idle": "2023-05-30T13:34:02.193748Z",
     "shell.execute_reply": "2023-05-30T13:34:02.191918Z"
    },
    "papermill": {
     "duration": 29.956454,
     "end_time": "2023-05-30T13:34:02.197167",
     "exception": false,
     "start_time": "2023-05-30T13:33:32.240713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/tsflex\r\n",
      "Processing /kaggle/input/tsflex/tsflex-0.3.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /opt/conda/lib/python3.7/site-packages (from tsflex) (1.3.5)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.62.3 in /opt/conda/lib/python3.7/site-packages (from tsflex) (4.64.1)\r\n",
      "Requirement already satisfied: multiprocess<0.71.0,>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from tsflex) (0.70.14)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.5 in /opt/conda/lib/python3.7/site-packages (from tsflex) (1.21.6)\r\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from tsflex) (0.3.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.3.5->tsflex) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.3.5->tsflex) (2022.7.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.3.5->tsflex) (1.16.0)\r\n",
      "Installing collected packages: tsflex\r\n",
      "Successfully installed tsflex-0.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: file:///kaggle/input/segalearn\r\n",
      "Processing /kaggle/input/segalearn/seglearn-1.2.5-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.21.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.7.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.0.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seglearn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seglearn) (3.1.0)\r\n",
      "Installing collected packages: seglearn\r\n",
      "Successfully installed seglearn-1.2.5\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import lightgbm\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import catboost\n",
    "import random\n",
    "random.seed(20)\n",
    "\n",
    "# Install tsflex and seglearn\n",
    "!pip install tsflex --no-index --find-links=file:///kaggle/input/tsflex\n",
    "!pip install seglearn --no-index --find-links=file:///kaggle/input/segalearn\n",
    "\n",
    "\n",
    "from seglearn.feature_functions import base_features, emg_features\n",
    "\n",
    "from tsflex.features import FeatureCollection, MultipleFeatureDescriptors\n",
    "from tsflex.features.integrations import seglearn_feature_dict_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f77756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.217341Z",
     "iopub.status.busy": "2023-05-30T13:34:02.215577Z",
     "iopub.status.idle": "2023-05-30T13:34:02.226794Z",
     "shell.execute_reply": "2023-05-30T13:34:02.225526Z"
    },
    "papermill": {
     "duration": 0.023962,
     "end_time": "2023-05-30T13:34:02.229589",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.205627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_invalid_events(df):\n",
    "    for e_type in [\"StartHesitation\", \"Turn\",'Walking']:\n",
    "        df.loc[(df[\"Valid\"] == False) | (df[\"Task\"] == False), e_type] = 0\n",
    "        \n",
    "    return df\n",
    "def min_max_feature(df, feature):\n",
    "    new_feature = f\"precent_prograss_{feature}\"\n",
    "    df[new_feature] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())\n",
    "    df[new_feature] = df[new_feature]                                                                                                     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb0441b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.248599Z",
     "iopub.status.busy": "2023-05-30T13:34:02.247502Z",
     "iopub.status.idle": "2023-05-30T13:34:02.263694Z",
     "shell.execute_reply": "2023-05-30T13:34:02.262232Z"
    },
    "papermill": {
     "duration": 0.029323,
     "end_time": "2023-05-30T13:34:02.266996",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.237673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
    "            if (col_type != 'object'):\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                continue\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3773df7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.285618Z",
     "iopub.status.busy": "2023-05-30T13:34:02.284452Z",
     "iopub.status.idle": "2023-05-30T13:34:02.606180Z",
     "shell.execute_reply": "2023-05-30T13:34:02.604946Z"
    },
    "papermill": {
     "duration": 0.334181,
     "end_time": "2023-05-30T13:34:02.609110",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.274929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbff87b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.627839Z",
     "iopub.status.busy": "2023-05-30T13:34:02.627309Z",
     "iopub.status.idle": "2023-05-30T13:34:02.638800Z",
     "shell.execute_reply": "2023-05-30T13:34:02.637376Z"
    },
    "papermill": {
     "duration": 0.024346,
     "end_time": "2023-05-30T13:34:02.641516",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.617170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FE_tsflex(df, is_td, isTest=False ):\n",
    "#     tdcsfog (128 timesteps per second)\n",
    "#     defog (100 timesteps per second).\n",
    "\n",
    "    if is_td:\n",
    "        second = 128\n",
    "    else:\n",
    "        second = 100\n",
    "\n",
    "    \n",
    "    if not isTest:\n",
    "        if \"Valid\" in df.columns:\n",
    "            df = fix_invalid_events(df)\n",
    "\n",
    "    for col in [\"Time\", \"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        df = min_max_feature(df, col)\n",
    "    \n",
    "    #TODO TDFLEX FEATURES\n",
    "    basic_feats = MultipleFeatureDescriptors(\n",
    "        functions=seglearn_feature_dict_wrapper(base_features()),\n",
    "        series_names=['AccV', 'AccML', 'AccAP'],\n",
    "        windows=[5_000, 10_000],\n",
    "        strides=[5_000, 10_000],\n",
    "    )\n",
    "\n",
    "    emg_feats = emg_features()\n",
    "    del emg_feats['simple square integral'] # is same as abs_energy (which is in base_features)\n",
    "\n",
    "    emg_feats = MultipleFeatureDescriptors(\n",
    "        functions=seglearn_feature_dict_wrapper(emg_feats),\n",
    "        series_names=['AccV', 'AccML', 'AccAP'],\n",
    "        windows=[5_000, 10_000],\n",
    "        strides=[5_000, 10_000],\n",
    "    )\n",
    "\n",
    "    fc = FeatureCollection([basic_feats, emg_feats])\n",
    "    df_feats = fc.calculate(df, return_df=True, include_final_window=True, approve_sparsity=True, window_idx=\"begin\")\n",
    "    df = df.merge(df_feats, how=\"left\", left_index=True, right_index=True).fillna(method=\"ffill\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35068f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.660624Z",
     "iopub.status.busy": "2023-05-30T13:34:02.659378Z",
     "iopub.status.idle": "2023-05-30T13:34:02.678589Z",
     "shell.execute_reply": "2023-05-30T13:34:02.677508Z"
    },
    "papermill": {
     "duration": 0.031432,
     "end_time": "2023-05-30T13:34:02.680913",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.649481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe_max_min(df, ranges_maxs):\n",
    "    new_cols = []\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        past_1 = df[col].shift(1).fillna(method=\"bfill\")\n",
    "        future_1 = df[col].shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "        is_max = np.where((df[col] > past_1) & (df[col] > future_1), True, False)\n",
    "        is_min = np.where((df[col] < past_1) & (df[col] < future_1), True, False)\n",
    "\n",
    "        last_max_temp = df[col].where(is_max).ffill().fillna(0)\n",
    "        last_min_temp = df[col].where(is_min).ffill().fillna(0)\n",
    "\n",
    "        maxs_df = pd.DataFrame(df[col].where(is_max).dropna())\n",
    "        maxs_df['Time'] = df[\"Time\"].where(is_max).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_max_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_max_{lag}_ago\")\n",
    "                    maxs_df[f\"{col}_max_{lag}_ago\"] = maxs_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].std(axis=1)\n",
    "\n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_maxs\", \n",
    "                            f\"{col}_max_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_mean_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_std_past_{lags_max}_maxs\"])\n",
    "\n",
    "\n",
    "        mins_df = pd.DataFrame(df[col].where(is_min).dropna())\n",
    "        mins_df['Time'] = df[\"Time\"].where(is_min).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_min_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_min_{lag}_ago\")\n",
    "                    mins_df[f\"{col}_min_{lag}_ago\"] = mins_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_mins\"] = mins_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_mins\"] = mins_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_mins\"] = mins_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_mins\"] = mins_df[cols_to_stat].std(axis=1)\n",
    "    \n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_mins\", \n",
    "                f\"{col}_max_past_{lags_max}_mins\",\n",
    "                f\"{col}_mean_past_{lags_max}_mins\",\n",
    "                f\"{col}_std_past_{lags_max}_mins\"])\n",
    "    for col in new_cols:\n",
    "        df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    del mins_df, maxs_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f2a9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.699801Z",
     "iopub.status.busy": "2023-05-30T13:34:02.698969Z",
     "iopub.status.idle": "2023-05-30T13:34:02.731028Z",
     "shell.execute_reply": "2023-05-30T13:34:02.729532Z"
    },
    "papermill": {
     "duration": 0.045507,
     "end_time": "2023-05-30T13:34:02.734445",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.688938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lag_feature(df,col_to_lag, lag, second,lag_scale=\"Time\" ):\n",
    "    if lag_scale == \"Time\":\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[col_to_lag].shift(lag*second).fillna(method=\"bfill\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[col_to_lag].shift(-lag*second).fillna(method=\"ffill\")\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].fillna(0)\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].fillna(0)\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].astype(\"float32\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].astype(\"float32\")\n",
    "                                                                                                               \n",
    "    return df\n",
    "\n",
    "def min_max_feature(df, feature):\n",
    "    new_feature = f\"precent_prograss_{feature}\"\n",
    "    df[new_feature] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())\n",
    "    df[new_feature] = df[new_feature]                                                                                                     \n",
    "    return df\n",
    "\n",
    "def fix_invalid_events(df):\n",
    "    for e_type in [\"StartHesitation\", \"Turn\",'Walking']:\n",
    "        df.loc[(df[\"Valid\"] == False) | (df[\"Task\"] == False), e_type] = 0\n",
    "        \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "- Stats in fences, for example, 2 seconds ago - 4 seconds ago,\n",
    "what was the mean? std? max? min?\n",
    "\"\"\"\n",
    "def fences_features(df,col, margin, width, stat, second):\n",
    "    stat_feature = f\"moving_{stat}_{col}_{width}\"\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[stat_feature].shift(margin*second).fillna(method=\"bfill\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[stat_feature].shift(-margin*second).fillna(method=\"ffill\")\n",
    "    \n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[f\"fence_{col}_m{margin}_w{width}_past\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[f\"fence_{col}_m{margin}_w{width}_future\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"]= df[f\"fence_{col}_m{margin}_w{width}_future\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"]= df[f\"fence_{col}_m{margin}_w{width}_past\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# def whole file stats - std/min/max/precentiles\n",
    "def whole_file_stats(df):\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        df[f\"graph_{col}_mean\"] = df[col].mean()\n",
    "        df[f\"graph_{col}_std\"] = df[col].std()\n",
    "        df[f\"graph_{col}_min\"] = df[col].min()\n",
    "        df[f\"graph_{col}_max\"] = df[col].max()\n",
    "        \n",
    "        half_file = df.shape[0] // 2\n",
    "        \n",
    "        first_half = df.iloc[:half_file]\n",
    "        second_half = df.iloc[half_file:]\n",
    "        \n",
    "        df[f\"graph_first_half_{col}_mean\"] = first_half[col].mean()\n",
    "        df[f\"graph_first_half_{col}_std\"] = first_half[col].std()\n",
    "        df[f\"graph_first_half_{col}_min\"] = first_half[col].min()\n",
    "        df[f\"graph_first_half_{col}_max\"] = first_half[col].max()\n",
    "        \n",
    "        df[f\"graph_second_half_{col}_mean\"] = second_half[col].mean()\n",
    "        df[f\"graph_second_half_{col}_std\"] = second_half[col].std()\n",
    "        df[f\"graph_second_half_{col}_min\"] = second_half[col].min()\n",
    "        df[f\"graph_second_half_{col}_max\"] = second_half[col].max()\n",
    "    return df\n",
    "        \n",
    "def FE(df, is_td, isTest=False ):\n",
    "#     tdcsfog (128 timesteps per second)\n",
    "#     defog (100 timesteps per second).\n",
    "\n",
    "    df = describe_max_min(df, [10,20, 30, 40])\n",
    "    df = whole_file_stats(df)\n",
    "\n",
    "    if is_td:\n",
    "        second = 128\n",
    "    else:\n",
    "        second = 100\n",
    "\n",
    "    \n",
    "    if not isTest:\n",
    "        if \"Valid\" in df.columns:\n",
    "            df = fix_invalid_events(df)\n",
    "                                                                                                               \n",
    "    for col in [\"Time\", \"AccV\", \"AccAP\"]:\n",
    "        df = min_max_feature(df, col)\n",
    "    \n",
    "    \n",
    "    for col in [\"AccV\", \"AccAP\"]:\n",
    "        new_col = col + \"_pct\"\n",
    "        df[new_col] = df[col].pct_change()\n",
    "        df[new_col] = df[new_col].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\")\n",
    "        df[new_col] = df[new_col].fillna(0).astype(\"float32\") # 0 to 0 returns null\n",
    "       \n",
    "                        \n",
    "        for margin in [5,10, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105]:\n",
    "            for w in[5,10]:\n",
    "                real_winow= second * w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[new_col].rolling(window = real_winow).std().fillna(method=\"bfill\")\n",
    "                # in case the file is smaller than w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[f\"moving_std_{new_col}_{w}\"].fillna(-1)\n",
    "                df = fences_features(df,new_col, margin=margin, width=w, stat=\"std\", second=second)\n",
    "                df[f\"moving_std_{new_col}_{w}\"] =  df[f\"moving_std_{new_col}_{w}\"].astype(\"float32\")\n",
    "        \n",
    "        df[f\"moving_std_all_{col}\"] = df[col].expanding().std().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_std_all_{col}\")\n",
    "        \n",
    "        df[f\"moving_mean_all_{col}\"] = df[col].expanding().mean().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_mean_all_{col}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8175ff87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.753951Z",
     "iopub.status.busy": "2023-05-30T13:34:02.753497Z",
     "iopub.status.idle": "2023-05-30T13:34:02.778395Z",
     "shell.execute_reply": "2023-05-30T13:34:02.777051Z"
    },
    "papermill": {
     "duration": 0.038315,
     "end_time": "2023-05-30T13:34:02.781728",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.743413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdcsfog_metadata = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/tdcsfog_metadata.csv\")\n",
    "# rememver, Visit only relevant for defog\n",
    "tdcsfog_metadata[\"Medication\"] = np.where(tdcsfog_metadata[\"Medication\"] == \"on\", 1, 0)\n",
    "tdcsfog_subject_dict =  dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Subject\"]))\n",
    "tdcsfog_medication_dict = dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Medication\"]))\n",
    "tdcsfog_Id_Visit = dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Visit\"]))\n",
    "tdcsfog_Id_Test  =dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcd3084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.800258Z",
     "iopub.status.busy": "2023-05-30T13:34:02.799802Z",
     "iopub.status.idle": "2023-05-30T13:34:02.831692Z",
     "shell.execute_reply": "2023-05-30T13:34:02.830298Z"
    },
    "papermill": {
     "duration": 0.044898,
     "end_time": "2023-05-30T13:34:02.834861",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.789963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "defog_metadata = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/defog_metadata.csv\")\n",
    "subjects = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/subjects.csv\")\n",
    "subjects[\"Visit\"] = subjects[\"Visit\"].fillna(1)\n",
    "subjects = subjects.drop_duplicates(subset=[\"Subject\", \"Visit\"])\n",
    "\n",
    "defog_metadata[\"Medication\"] = np.where(defog_metadata[\"Medication\"] == \"on\", 1, 0)\n",
    "defog_subject_dict = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Subject\"]))\n",
    "defog_medication_dict = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Medication\"]))\n",
    "defog_Id_Visit = dict(zip(defog_metadata[\"Id\"], defog_metadata[\"Visit\"]))\n",
    "defog_Id_Test  =dict(zip(defog_metadata[\"Id\"], np.zeros(defog_metadata.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095ffcb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.853223Z",
     "iopub.status.busy": "2023-05-30T13:34:02.852735Z",
     "iopub.status.idle": "2023-05-30T13:34:02.860749Z",
     "shell.execute_reply": "2023-05-30T13:34:02.859376Z"
    },
    "papermill": {
     "duration": 0.020364,
     "end_time": "2023-05-30T13:34:02.863311",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.842947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects[\"UPDRSIII_On\"] = subjects[\"UPDRSIII_On\"].fillna(0)\n",
    "subjects[\"UPDRSIII_Off\"] = subjects[\"UPDRSIII_Off\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029efcb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.881804Z",
     "iopub.status.busy": "2023-05-30T13:34:02.881317Z",
     "iopub.status.idle": "2023-05-30T13:34:02.889126Z",
     "shell.execute_reply": "2023-05-30T13:34:02.887611Z"
    },
    "papermill": {
     "duration": 0.020255,
     "end_time": "2023-05-30T13:34:02.891787",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.871532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_outliers(df):\n",
    "    for col in ['AccV','AccML','AccV']:\n",
    "        max_value = df[col].quantile(q=0.99)\n",
    "        min_value = df[col].quantile(q=0.01)\n",
    "        df[col] = np.where(df[col] > max_value, max_value, df[col])\n",
    "        df[col] = np.where(df[col] < min_value, min_value, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9aee5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.909880Z",
     "iopub.status.busy": "2023-05-30T13:34:02.909428Z",
     "iopub.status.idle": "2023-05-30T13:34:02.917561Z",
     "shell.execute_reply": "2023-05-30T13:34:02.916257Z"
    },
    "papermill": {
     "duration": 0.020493,
     "end_time": "2023-05-30T13:34:02.920114",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.899621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    class_dict = {0: \"StartHesitation\", 1: \"Turn\", 2:\"Walking\", 3:\"None\"}\n",
    "    df[\"target\"] = 3\n",
    "    df[\"target\"] = np.where(df[\"StartHesitation\"] == 1, 0, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Turn\"] == 1, 1, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Walking\"] == 1, 2, df[\"target\"] )\n",
    "    \n",
    "    df = df.drop([\"StartHesitation\", \"Turn\", \"Walking\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbfe441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.938729Z",
     "iopub.status.busy": "2023-05-30T13:34:02.938139Z",
     "iopub.status.idle": "2023-05-30T13:34:02.955877Z",
     "shell.execute_reply": "2023-05-30T13:34:02.954048Z"
    },
    "papermill": {
     "duration": 0.030962,
     "end_time": "2023-05-30T13:34:02.958922",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.927960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(base,isTest=False, black_list = []):\n",
    "    train= pd.DataFrame()\n",
    "    if \"tdcsfog\" in base:\n",
    "        is_td = True\n",
    "\n",
    "    else:\n",
    "        is_td = False\n",
    "    \n",
    "    for train_path in tqdm(os.listdir(base)):\n",
    "        file_path = base + '/'+train_path\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        df = flat_outliers(df)\n",
    "        df = FE(df, is_td)\n",
    "        \n",
    "        df_time = df[\"Time\"].copy()\n",
    "        df = df.set_index(\"Time\")\n",
    "        df[\"Time\"] = df_time\n",
    "        del df_time\n",
    "        gc.collect()\n",
    "        \n",
    "        df = FE_tsflex(df, is_td)\n",
    "        \n",
    "        if not isTest:\n",
    "            df = create_target(df)\n",
    "            \n",
    "        df[\"file\"] = train_path.split(\".\")[0]\n",
    "        df[\"id\"] = df[\"file\"].astype(\"str\") + \"_\" + df[\"Time\"].astype(\"str\")\n",
    "        \n",
    "        dot_index = train_path.index(\".\")\n",
    "        file_id = train_path[:dot_index]\n",
    "        \n",
    "        if \"tdcsfog\" in base:\n",
    "            df[\"Subject\"] = tdcsfog_subject_dict[file_id]\n",
    "            df[\"Medication\"] =  tdcsfog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = tdcsfog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =tdcsfog_Id_Test[file_id]\n",
    "\n",
    "        else:\n",
    "            df[\"Subject\"] = defog_subject_dict[file_id]\n",
    "            df[\"Medication\"] = defog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = defog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =defog_Id_Test[file_id]\n",
    "\n",
    "        if train.shape[0] == 0:\n",
    "            cur_black_list = [c for c in black_list if c in df.columns]\n",
    "            coverted_first = reduce_memory_usage(df.drop(cur_black_list, axis = 1))\n",
    "            new_dtypes_dict = coverted_first.dtypes.to_dict()\n",
    "            train_cols = [c for c in df.columns if c not in cur_black_list]\n",
    "            \n",
    "        train = train.append(df[train_cols].astype(new_dtypes_dict))[train_cols]\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "    train = reduce_memory_usage(train)\n",
    "    train.reset_index(drop=True, inplace=True)     \n",
    "    for col in train.columns:\n",
    "        if train[col].dtype != \"object\":\n",
    "            if train[col].max() > 99999 or train[col].min()<-9999:\n",
    "                train[col]=train[col].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "940d2d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:02.977272Z",
     "iopub.status.busy": "2023-05-30T13:34:02.976771Z",
     "iopub.status.idle": "2023-05-30T13:34:02.984905Z",
     "shell.execute_reply": "2023-05-30T13:34:02.983544Z"
    },
    "papermill": {
     "duration": 0.020464,
     "end_time": "2023-05-30T13:34:02.987507",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.967043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_white_list(models):\n",
    "    white_list = set([])\n",
    "    for model_name in models: \n",
    "        model = models[model_name][0]\n",
    "        if \"xgboost\" in model_name :\n",
    "            model_cols = model.get_booster().feature_names\n",
    "\n",
    "        elif \"lgbm\" in model_name:\n",
    "            model_cols = model.feature_name_\n",
    "\n",
    "        elif \"rf\" in model_name or \"adaboost\" in model_name: \n",
    "            model_cols =  model.feature_names_in_\n",
    "        else:\n",
    "            model_cols = model.feature_names_\n",
    "\n",
    "        white_list = white_list.union(set(model_cols)).union([\"Subject\", \"Visit\",\"id\"])\n",
    "        \n",
    "    return white_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0491fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:03.005836Z",
     "iopub.status.busy": "2023-05-30T13:34:03.005343Z",
     "iopub.status.idle": "2023-05-30T13:34:03.348054Z",
     "shell.execute_reply": "2023-05-30T13:34:03.346784Z"
    },
    "papermill": {
     "duration": 0.355984,
     "end_time": "2023-05-30T13:34:03.351475",
     "exception": false,
     "start_time": "2023-05-30T13:34:02.995491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "catboost_tsflex_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-catboost-v9-tsflex/model_dict_catboost_full.pkl\", \"rb\"))\n",
    "xgboost_tsflex_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-xgboost-v9-tsflex/model_dict_xgboost_full.pkl\", \"rb\"))\n",
    "lgbm_tsflex_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-lgbm-v9-tsflex/model_dict_lgbm_full.pkl\", \"rb\"))\n",
    "rf_tsflex_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-rf-v9-tsflex/model_dict_rf_full.pkl\", \"rb\"))\n",
    "adaboost_tsflex_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-adaboost-v9-tsflex/model_dict_adaboost_full.pkl\", \"rb\"))\n",
    "\n",
    "catboost_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-catboost-v9/model_dict_catboost_full.pkl\", \"rb\"))\n",
    "xgboost_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-xgboost-v9/model_dict_xgboost_full.pkl\", \"rb\"))\n",
    "lgbm_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-lgbm-v9/model_dict_lgbm_full.pkl\", \"rb\"))\n",
    "rf_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-rf-v9/model_dict_rf_full.pkl\", \"rb\"))\n",
    "adaboost_model_dict = pickle.load(open(\"/kaggle/input/make-final-model-full-adaboost-v9/model_dict_adaboost_full.pkl\", \"rb\"))\n",
    "\n",
    "white_list = pickle.load(open(\"/kaggle/input/black-list-v9/white_list.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376eecb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:03.371915Z",
     "iopub.status.busy": "2023-05-30T13:34:03.371405Z",
     "iopub.status.idle": "2023-05-30T13:34:46.739585Z",
     "shell.execute_reply": "2023-05-30T13:34:46.737549Z"
    },
    "papermill": {
     "duration": 43.382901,
     "end_time": "2023-05-30T13:34:46.743127",
     "exception": false,
     "start_time": "2023-05-30T13:34:03.360226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 8.70 MB\n",
      "Memory usage became:  2.8541927337646484  MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.73 MB\n",
      "Memory usage became:  2.728178024291992  MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 523.85 MB\n",
      "Memory usage became:  170.85753631591797  MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 162.79 MB\n",
      "Memory usage became:  162.7949981689453  MB\n"
     ]
    }
   ],
   "source": [
    "black_list = pickle.load(open(\"/kaggle/input/black-list-v9/black_list.pkl\", \"rb\"))\n",
    "td_test = make_df(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog\",black_list= black_list, isTest=True)\n",
    "de_test = make_df(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog\", black_list = black_list,isTest=True)\n",
    "\n",
    "\n",
    "ss_de = ss.loc[ss.Id.isin(de_test.id)].reset_index(drop=True)\n",
    "ss_td = ss.loc[ss.Id.isin(td_test.id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025904af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:46.765035Z",
     "iopub.status.busy": "2023-05-30T13:34:46.764523Z",
     "iopub.status.idle": "2023-05-30T13:34:50.358018Z",
     "shell.execute_reply": "2023-05-30T13:34:50.356342Z"
    },
    "papermill": {
     "duration": 3.608364,
     "end_time": "2023-05-30T13:34:50.360956",
     "exception": false,
     "start_time": "2023-05-30T13:34:46.752592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4682, 290)\n",
      "(4682, 296)\n",
      "(281688, 290)\n",
      "(281688, 296)\n",
      "Memory usage of dataframe is 2.94 MB\n",
      "Memory usage became:  2.7683639526367188  MB\n",
      "Memory usage of dataframe is 175.69 MB\n",
      "Memory usage became:  165.2127456665039  MB\n"
     ]
    }
   ],
   "source": [
    "print(td_test.shape)\n",
    "# merging only on Subject because Visit is relevant for defog only\n",
    "td_test = td_test.merge(subjects.drop(\"Visit\",axis = 1),\n",
    "                                    on=[\"Subject\"], how=\"left\")\n",
    "print(td_test.shape)\n",
    "\n",
    "print(de_test.shape)\n",
    "de_test = de_test.merge(subjects, on=[\"Subject\",\"Visit\"], how=\"left\")\n",
    "print(de_test.shape)\n",
    "\n",
    "td_test['Sex'] = np.where(td_test['Sex'] == \"M\", 1, 0)\n",
    "de_test['Sex'] = np.where(de_test['Sex'] == \"M\", 1, 0)\n",
    "\n",
    "td_test = reduce_memory_usage(td_test)\n",
    "de_test = reduce_memory_usage(de_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dca7790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:50.382114Z",
     "iopub.status.busy": "2023-05-30T13:34:50.381655Z",
     "iopub.status.idle": "2023-05-30T13:34:50.394390Z",
     "shell.execute_reply": "2023-05-30T13:34:50.393091Z"
    },
    "papermill": {
     "duration": 0.026469,
     "end_time": "2023-05-30T13:34:50.396918",
     "exception": false,
     "start_time": "2023-05-30T13:34:50.370449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_y(y):\n",
    "    return y - 1 # (1,2,3) -> (0,1,2)\n",
    "\n",
    "def predict(test, train_cols, model, model_name=\"dummy\", scaler = None):\n",
    "    preds = model.predict_proba(test[train_cols])\n",
    "\n",
    "    preds_df = pd.DataFrame()\n",
    "    preds_df[\"Id\"] = test[\"id\"]\n",
    "\n",
    "\n",
    "    preds_df[\"StartHesitation\"] = [p[0] for p in preds]\n",
    "    preds_df[\"Turn\"] = [p[1] for p in preds]\n",
    "    preds_df[\"Walking\"] = [p[2] for p in preds]\n",
    "\n",
    "    preds_df.index=test.index\n",
    "    return preds_df\n",
    "\n",
    "def combine_preds(preds_td, preds_de, ss):\n",
    "    ss = ss.drop([\"StartHesitation\", \"Turn\", \"Walking\"], axis = 1)\n",
    "    \n",
    "    ss = ss.merge(preds_td, on=\"Id\", how=\"left\")\n",
    "    ss = ss.merge(preds_de, on=\"Id\", how=\"left\",  suffixes = (\"_td\", \"_de\"))\n",
    "    \n",
    "    ss[\"StartHesitation\"] = np.where(ss[\"StartHesitation_td\"].isna(),ss[\"StartHesitation_de\"],  ss[\"StartHesitation_td\"])\n",
    "    ss[\"Turn\"] = np.where(ss[\"Turn_td\"].isna(),ss[\"Turn_de\"],  ss[\"Turn_td\"])\n",
    "    ss[\"Walking\"] = np.where(ss[\"Walking_td\"].isna(),ss[\"Walking_de\"],  ss[\"Walking_td\"])\n",
    "    \n",
    "    return ss[[\"Id\",\"StartHesitation\", \"Turn\", \"Walking\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eecf902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:34:50.417900Z",
     "iopub.status.busy": "2023-05-30T13:34:50.416871Z",
     "iopub.status.idle": "2023-05-30T13:35:22.796942Z",
     "shell.execute_reply": "2023-05-30T13:35:22.795183Z"
    },
    "papermill": {
     "duration": 32.394602,
     "end_time": "2023-05-30T13:35:22.800750",
     "exception": false,
     "start_time": "2023-05-30T13:34:50.406148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# catboost\n",
    "preds_td_catboost = predict(td_test, train_cols=catboost_model_dict[\"features\"], model=catboost_model_dict[\"model\"])\n",
    "preds_de_catboost = predict(de_test, train_cols=catboost_model_dict[\"features\"], model=catboost_model_dict[\"model\"])\n",
    "final_ss_catboost = combine_preds(preds_td_catboost, preds_de_catboost, ss.copy())\n",
    "\n",
    "#xgb\n",
    "preds_td_xgboost = predict(td_test, train_cols=xgboost_model_dict[\"features\"], model=xgboost_model_dict[\"model\"])\n",
    "preds_de_xgboost = predict(de_test,train_cols=xgboost_model_dict[\"features\"], model=xgboost_model_dict[\"model\"])\n",
    "final_ss_xgboost = combine_preds(preds_td_xgboost, preds_de_xgboost, ss.copy())\n",
    "\n",
    "\n",
    "#lgbm\n",
    "preds_td_lgbm = predict(td_test, train_cols=lgbm_model_dict[\"features\"], model=lgbm_model_dict[\"model\"])\n",
    "preds_de_lgbm = predict(de_test, train_cols=lgbm_model_dict[\"features\"], model = lgbm_model_dict[\"model\"])\n",
    "final_ss_lgbm = combine_preds(preds_td_lgbm, preds_de_lgbm, ss.copy())\n",
    "\n",
    "\n",
    "#rf\n",
    "preds_td_rf = predict(td_test, train_cols=rf_model_dict[\"features\"], model=rf_model_dict[\"model\"])\n",
    "preds_de_rf = predict(de_test,train_cols=rf_model_dict[\"features\"], model=rf_model_dict[\"model\"])\n",
    "final_ss_rf = combine_preds(preds_td_rf, preds_de_rf, ss.copy())\n",
    "\n",
    "#adaboost\n",
    "preds_td_adaboost = predict(td_test,  train_cols=adaboost_model_dict[\"features\"], model=adaboost_model_dict[\"model\"])\n",
    "preds_de_adaboost = predict(de_test, train_cols=adaboost_model_dict[\"features\"], model=adaboost_model_dict[\"model\"])\n",
    "final_ss_adaboost = combine_preds(preds_td_adaboost, preds_de_adaboost, ss.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2f5a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:35:22.822544Z",
     "iopub.status.busy": "2023-05-30T13:35:22.822034Z",
     "iopub.status.idle": "2023-05-30T13:35:42.332175Z",
     "shell.execute_reply": "2023-05-30T13:35:42.330821Z"
    },
    "papermill": {
     "duration": 19.524806,
     "end_time": "2023-05-30T13:35:42.335490",
     "exception": false,
     "start_time": "2023-05-30T13:35:22.810684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# catboost\n",
    "\n",
    "preds_td_catboost_tsflex = predict(td_test, train_cols=catboost_tsflex_model_dict[\"features\"], model=catboost_tsflex_model_dict[\"model\"])\n",
    "preds_de_catboost_tsflex = predict(de_test, train_cols=catboost_tsflex_model_dict[\"features\"], model=catboost_tsflex_model_dict[\"model\"])\n",
    "final_ss_tsflex_catboost = combine_preds(preds_td_catboost_tsflex, preds_de_catboost_tsflex, ss.copy())\n",
    "\n",
    "#xgb\n",
    "preds_td_xgboost_tsflex = predict(td_test, train_cols=xgboost_tsflex_model_dict[\"features\"], model=xgboost_tsflex_model_dict[\"model\"])\n",
    "preds_de_xgboost_tsflex = predict(de_test,train_cols=xgboost_tsflex_model_dict[\"features\"], model=xgboost_tsflex_model_dict[\"model\"])\n",
    "final_ss_tsflex_xgboost = combine_preds(preds_td_xgboost_tsflex, preds_de_xgboost_tsflex, ss.copy())\n",
    "\n",
    "\n",
    "#lgbm\n",
    "preds_td_lgbm_tsflex = predict(td_test, train_cols=lgbm_tsflex_model_dict[\"features\"], model=lgbm_tsflex_model_dict[\"model\"])\n",
    "preds_de_lgbm_tsflex = predict(de_test, train_cols=lgbm_tsflex_model_dict[\"features\"], model = lgbm_tsflex_model_dict[\"model\"])\n",
    "final_ss_tsflex_lgbm = combine_preds(preds_td_lgbm_tsflex, preds_de_lgbm_tsflex, ss.copy())\n",
    "\n",
    "\n",
    "#rf\n",
    "preds_td_rf_tsflex = predict(td_test, train_cols=rf_tsflex_model_dict[\"features\"], model=rf_tsflex_model_dict[\"model\"])\n",
    "preds_de_rf_tsflex = predict(de_test,train_cols=rf_tsflex_model_dict[\"features\"], model=rf_tsflex_model_dict[\"model\"])\n",
    "final_ss_tsflex_rf = combine_preds(preds_td_rf_tsflex, preds_de_rf_tsflex, ss.copy())\n",
    "\n",
    "#adaboost\n",
    "preds_td_adaboost_tsflex = predict(td_test,  train_cols=adaboost_tsflex_model_dict[\"features\"], model=adaboost_tsflex_model_dict[\"model\"])\n",
    "preds_de_adaboost_tsflex = predict(de_test, train_cols=adaboost_tsflex_model_dict[\"features\"], model=adaboost_tsflex_model_dict[\"model\"])\n",
    "final_ss_tsflex_adaboost = combine_preds(preds_td_adaboost_tsflex, preds_de_adaboost_tsflex, ss.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733826c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:35:42.356542Z",
     "iopub.status.busy": "2023-05-30T13:35:42.356026Z",
     "iopub.status.idle": "2023-05-30T13:35:42.365889Z",
     "shell.execute_reply": "2023-05-30T13:35:42.364413Z"
    },
    "papermill": {
     "duration": 0.023747,
     "end_time": "2023-05-30T13:35:42.368732",
     "exception": false,
     "start_time": "2023-05-30T13:35:42.344985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "finals = {\"final_ss_catboost\": final_ss_catboost, \"final_ss_xgboost\": final_ss_xgboost,\n",
    "         \"final_ss_lgbm\": final_ss_lgbm,\"final_ss_rf\":final_ss_rf, 'final_ss_adaboost':final_ss_adaboost,\n",
    "        \"final_ss_tsflex_catboost\":final_ss_tsflex_catboost, \"final_ss_tsflex_xgboost\":final_ss_tsflex_xgboost,\n",
    "          \"final_ss_tsflex_lgbm\":final_ss_tsflex_lgbm, \"final_ss_tsflex_rf\":final_ss_tsflex_rf,\n",
    "             \"final_ss_tsflex_adaboost\":final_ss_tsflex_adaboost }\n",
    " # from baging lab\n",
    "weights = {'final_ss_rf': 0.3, 'final_ss_lgbm': 2,\n",
    "           'final_ss_xgboost': 3, 'final_ss_catboost': 3, 'final_ss_adaboost': 0.0654058370958252,\n",
    "           'final_ss_tsflex_rf': 0.3, 'final_ss_tsflex_lgbm': 2, \n",
    "           'final_ss_tsflex_xgboost': 3.5, 'final_ss_tsflex_catboost': 3, \n",
    "           'final_ss_tsflex_adaboost': 0.7}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ea10d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:35:42.390824Z",
     "iopub.status.busy": "2023-05-30T13:35:42.390353Z",
     "iopub.status.idle": "2023-05-30T13:35:42.670658Z",
     "shell.execute_reply": "2023-05-30T13:35:42.669251Z"
    },
    "papermill": {
     "duration": 0.295011,
     "end_time": "2023-05-30T13:35:42.673947",
     "exception": false,
     "start_time": "2023-05-30T13:35:42.378936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "total_models = 0\n",
    "to_sub=pd.DataFrame()\n",
    "for final_name in finals:\n",
    "    final = finals[final_name]\n",
    "    sh_cols = [c for c in final.columns if \"StartH\" in c]\n",
    "    turn_cols= [c for c in final.columns if \"Turn\" in c]\n",
    "    walking_cols= [c for c in final.columns if \"Walking\" in c]\n",
    "    \n",
    "    total_models += len(sh_cols)\n",
    "    if c== 0:\n",
    "        to_sub[\"StartHesitation\"]=final[sh_cols].sum(axis=1) * weights[final_name]\n",
    "        to_sub[\"Turn\"]=final[turn_cols].sum(axis=1) * weights[final_name]\n",
    "        to_sub[\"Walking\"]=final[walking_cols].sum(axis=1) * weights[final_name]\n",
    "    \n",
    "    else:\n",
    "        to_sub[\"StartHesitation\"] += final[sh_cols].sum(axis=1) * weights[final_name]\n",
    "        to_sub[\"Turn\"] += final[turn_cols].sum(axis=1) * weights[final_name]\n",
    "        to_sub[\"Walking\"] += final[walking_cols].sum(axis=1) * weights[final_name]\n",
    "    c += 1\n",
    "\n",
    "to_sub = to_sub / total_models\n",
    "to_sub.insert(0, \"Id\",final_ss_xgboost[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "158308c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:35:42.695508Z",
     "iopub.status.busy": "2023-05-30T13:35:42.694955Z",
     "iopub.status.idle": "2023-05-30T13:35:44.270991Z",
     "shell.execute_reply": "2023-05-30T13:35:44.269622Z"
    },
    "papermill": {
     "duration": 1.590769,
     "end_time": "2023-05-30T13:35:44.274267",
     "exception": false,
     "start_time": "2023-05-30T13:35:42.683498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 145.985907,
   "end_time": "2023-05-30T13:35:45.711587",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-30T13:33:19.725680",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
