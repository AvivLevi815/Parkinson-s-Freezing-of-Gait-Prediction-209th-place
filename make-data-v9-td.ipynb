{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a553bba4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:26.475682Z",
     "iopub.status.busy": "2023-05-26T11:48:26.475102Z",
     "iopub.status.idle": "2023-05-26T11:48:30.069442Z",
     "shell.execute_reply": "2023-05-26T11:48:30.067828Z"
    },
    "papermill": {
     "duration": 3.607633,
     "end_time": "2023-05-26T11:48:30.073141",
     "exception": false,
     "start_time": "2023-05-26T11:48:26.465508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option(\"max_columns\", 50)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fdce6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.088565Z",
     "iopub.status.busy": "2023-05-26T11:48:30.088088Z",
     "iopub.status.idle": "2023-05-26T11:48:30.101831Z",
     "shell.execute_reply": "2023-05-26T11:48:30.100675Z"
    },
    "papermill": {
     "duration": 0.025354,
     "end_time": "2023-05-26T11:48:30.105069",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.079715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "black_list = pickle.load(open(\"/kaggle/input/black-list-v8-1/black_list.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cc8f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.120092Z",
     "iopub.status.busy": "2023-05-26T11:48:30.119653Z",
     "iopub.status.idle": "2023-05-26T11:48:30.168042Z",
     "shell.execute_reply": "2023-05-26T11:48:30.166895Z"
    },
    "papermill": {
     "duration": 0.059379,
     "end_time": "2023-05-26T11:48:30.171023",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.111644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdcsfog_metadata = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/tdcsfog_metadata.csv\")\n",
    "\n",
    "subjects = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/subjects.csv\")\n",
    "# rememver, Visit only relevant for defog\n",
    "tdcsfog_metadata[\"Medication\"] = np.where(tdcsfog_metadata[\"Medication\"] == \"on\", 1, 0)\n",
    "tdcsfog_subject_dict =  dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Subject\"]))\n",
    "tdcsfog_medication_dict = dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Medication\"]))\n",
    "tdcsfog_Id_Visit = dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Visit\"]))\n",
    "tdcsfog_Id_Test  =dict(zip(tdcsfog_metadata[\"Id\"], tdcsfog_metadata[\"Test\"]))\n",
    "\n",
    "\n",
    "subjects[\"UPDRSIII_On\"] = subjects[\"UPDRSIII_On\"].fillna(0)\n",
    "subjects[\"UPDRSIII_Off\"] = subjects[\"UPDRSIII_Off\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e175a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.186451Z",
     "iopub.status.busy": "2023-05-26T11:48:30.185564Z",
     "iopub.status.idle": "2023-05-26T11:48:30.215481Z",
     "shell.execute_reply": "2023-05-26T11:48:30.213871Z"
    },
    "papermill": {
     "duration": 0.041231,
     "end_time": "2023-05-26T11:48:30.218794",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.177563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe_max_min(df, ranges_maxs):\n",
    "    new_cols = []\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        past_1 = df[col].shift(1).fillna(method=\"bfill\")\n",
    "        future_1 = df[col].shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "        is_max = np.where((df[col] > past_1) & (df[col] > future_1), True, False)\n",
    "        is_min = np.where((df[col] < past_1) & (df[col] < future_1), True, False)\n",
    "\n",
    "        last_max_temp = df[col].where(is_max).ffill().fillna(0)\n",
    "        last_min_temp = df[col].where(is_min).ffill().fillna(0)\n",
    "\n",
    "        maxs_df = pd.DataFrame(df[col].where(is_max).dropna())\n",
    "        maxs_df['Time'] = df[\"Time\"].where(is_max).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_max_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_max_{lag}_ago\")\n",
    "                    maxs_df[f\"{col}_max_{lag}_ago\"] = maxs_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_maxs\"] = maxs_df[cols_to_stat].std(axis=1)\n",
    "\n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_maxs\", \n",
    "                            f\"{col}_max_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_mean_past_{lags_max}_maxs\",\n",
    "                            f\"{col}_std_past_{lags_max}_maxs\"])\n",
    "\n",
    "\n",
    "        mins_df = pd.DataFrame(df[col].where(is_min).dropna())\n",
    "        mins_df['Time'] = df[\"Time\"].where(is_min).dropna().astype(\"int\")\n",
    "\n",
    "        cols_to_stat = []\n",
    "        for lags_max in ranges_maxs:\n",
    "            lags = list(range(1,lags_max+1))\n",
    "            for lag in lags:\n",
    "                if f\"{col}_min_{lag}_ago\" not in cols_to_stat:\n",
    "                    cols_to_stat.append(f\"{col}_min_{lag}_ago\")\n",
    "                    mins_df[f\"{col}_min_{lag}_ago\"] = mins_df[col].shift(lag).fillna(method=\"bfill\")\n",
    "\n",
    "            df[f\"{col}_min_past_{lags_max}_mins\"] = mins_df[cols_to_stat].min(axis=1)\n",
    "            df[f\"{col}_max_past_{lags_max}_mins\"] = mins_df[cols_to_stat].max(axis=1)\n",
    "            df[f\"{col}_mean_past_{lags_max}_mins\"] = mins_df[cols_to_stat].mean(axis=1)\n",
    "            df[f\"{col}_std_past_{lags_max}_mins\"] = mins_df[cols_to_stat].std(axis=1)\n",
    "    \n",
    "            new_cols.extend([f\"{col}_min_past_{lags_max}_mins\", \n",
    "                f\"{col}_max_past_{lags_max}_mins\",\n",
    "                f\"{col}_mean_past_{lags_max}_mins\",\n",
    "                f\"{col}_std_past_{lags_max}_mins\"])\n",
    "    for col in new_cols:\n",
    "        df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    del mins_df, maxs_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4380239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.234333Z",
     "iopub.status.busy": "2023-05-26T11:48:30.233875Z",
     "iopub.status.idle": "2023-05-26T11:48:30.280184Z",
     "shell.execute_reply": "2023-05-26T11:48:30.278523Z"
    },
    "papermill": {
     "duration": 0.059029,
     "end_time": "2023-05-26T11:48:30.284114",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.225085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lag_feature(df,col_to_lag, lag, second,lag_scale=\"Time\" ):\n",
    "    if lag_scale == \"Time\":\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[col_to_lag].shift(lag*second).fillna(method=\"bfill\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[col_to_lag].shift(-lag*second).fillna(method=\"ffill\")\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].fillna(0)\n",
    "        if df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].isna().sum() > 0:\n",
    "            df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].fillna(0)\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_ago\"].astype(\"float32\")\n",
    "        df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"] = df[f\"{col_to_lag}_{lag}_{lag_scale}_from_now\"].astype(\"float32\")\n",
    "                                                                                                               \n",
    "    return df\n",
    "\n",
    "def min_max_feature(df, feature):\n",
    "    new_feature = f\"precent_prograss_{feature}\"\n",
    "    df[new_feature] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())\n",
    "    df[new_feature] = df[new_feature].astype(\"float16\")                                                                                                           \n",
    "    return df\n",
    "\n",
    "def fix_invalid_events(df):\n",
    "    for e_type in [\"StartHesitation\", \"Turn\",'Walking']:\n",
    "        df.loc[(df[\"Valid\"] == False) | (df[\"Task\"] == False), e_type] = 0\n",
    "        \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "- Stats in fences, for example, 2 seconds ago - 4 seconds ago,\n",
    "what was the mean? std? max? min?\n",
    "\"\"\"\n",
    "def fences_features(df,col, margin, width, stat, second):\n",
    "    stat_feature = f\"moving_{stat}_{col}_{width}\"\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[stat_feature].shift(margin*second).fillna(method=\"bfill\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[stat_feature].shift(-margin*second).fillna(method=\"ffill\")\n",
    "    \n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"] = df[f\"fence_{col}_m{margin}_w{width}_past\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"] = df[f\"fence_{col}_m{margin}_w{width}_future\"].fillna(0)\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_future\"]= df[f\"fence_{col}_m{margin}_w{width}_future\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "    df[f\"fence_{col}_m{margin}_w{width}_past\"]= df[f\"fence_{col}_m{margin}_w{width}_past\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(-1).astype(\"float32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# def whole file stats - std/min/max/precentiles\n",
    "def whole_file_stats(df):\n",
    "    for col in [\"AccV\", \"AccML\", \"AccAP\"]:\n",
    "        df[f\"graph_{col}_mean\"] = df[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_{col}_std\"] = df[col].std().astype(\"float16\")\n",
    "        df[f\"graph_{col}_min\"] = df[col].min().astype(\"float16\")\n",
    "        df[f\"graph_{col}_max\"] = df[col].max().astype(\"float16\")\n",
    "        \n",
    "        half_file = df.shape[0] // 2\n",
    "        \n",
    "        first_half = df.iloc[:half_file]\n",
    "        second_half = df.iloc[half_file:]\n",
    "        \n",
    "        df[f\"graph_first_half_{col}_mean\"] = first_half[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_std\"] = first_half[col].std().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_min\"] = first_half[col].min().astype(\"float16\")\n",
    "        df[f\"graph_first_half_{col}_max\"] = first_half[col].max().astype(\"float16\")\n",
    "        \n",
    "        df[f\"graph_second_half_{col}_mean\"] = second_half[col].mean().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_std\"] = second_half[col].std().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_min\"] = second_half[col].min().astype(\"float16\")\n",
    "        df[f\"graph_second_half_{col}_max\"] = second_half[col].max().astype(\"float16\")\n",
    "    return df\n",
    "        \n",
    "def FE(df, is_td, isTest=False ):\n",
    "#     tdcsfog (128 timesteps per second)\n",
    "#     defog (100 timesteps per second).\n",
    "\n",
    "    df = describe_max_min(df, [10,20, 30, 40])\n",
    "    df = whole_file_stats(df)\n",
    "\n",
    "    if is_td:\n",
    "        second = 128\n",
    "    else:\n",
    "        second = 100\n",
    "\n",
    "    \n",
    "    if not isTest:\n",
    "        if \"Valid\" in df.columns:\n",
    "            df = fix_invalid_events(df)\n",
    "                                                                                                               \n",
    "    for col in [\"Time\", \"AccV\", \"AccAP\"]:\n",
    "        df = min_max_feature(df, col)\n",
    "    \n",
    "    \n",
    "    for col in [\"AccV\", \"AccAP\"]:\n",
    "        new_col = col + \"_pct\"\n",
    "        df[new_col] = df[col].pct_change()\n",
    "        df[new_col] = df[new_col].replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\")\n",
    "        df[new_col] = df[new_col].fillna(0).astype(\"float32\") # 0 to 0 returns null\n",
    "       \n",
    "                        \n",
    "        for margin in [5,10, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105]:\n",
    "            for w in[5,10]:\n",
    "                real_winow= second * w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[new_col].rolling(window = real_winow).std().fillna(method=\"bfill\")\n",
    "                # in case the file is smaller than w\n",
    "                df[f\"moving_std_{new_col}_{w}\"] = df[f\"moving_std_{new_col}_{w}\"].fillna(-1)\n",
    "                df = fences_features(df,new_col, margin=margin, width=w, stat=\"std\", second=second)\n",
    "                df[f\"moving_std_{new_col}_{w}\"] =  df[f\"moving_std_{new_col}_{w}\"].astype(\"float32\")\n",
    "        \n",
    "        df[f\"moving_std_all_{col}\"] = df[col].expanding().std().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_std_all_{col}\")\n",
    "        \n",
    "        df[f\"moving_mean_all_{col}\"] = df[col].expanding().mean().fillna(method=\"bfill\")\n",
    "        df = min_max_feature(df, f\"moving_mean_all_{col}\")\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437146da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.299758Z",
     "iopub.status.busy": "2023-05-26T11:48:30.299298Z",
     "iopub.status.idle": "2023-05-26T11:48:30.308294Z",
     "shell.execute_reply": "2023-05-26T11:48:30.306714Z"
    },
    "papermill": {
     "duration": 0.020631,
     "end_time": "2023-05-26T11:48:30.311476",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.290845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target\n",
    "def create_target(df):\n",
    "    class_dict = {0: \"StartHesitation\", 1: \"Turn\", 2:\"Walking\", 3:\"None\"}\n",
    "    df[\"target\"] = 3\n",
    "    df[\"target\"] = np.where(df[\"StartHesitation\"] == 1, 0, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Turn\"] == 1, 1, df[\"target\"] )\n",
    "    df[\"target\"] = np.where(df[\"Walking\"] == 1, 2, df[\"target\"] )\n",
    "    \n",
    "    df = df.drop([\"StartHesitation\", \"Turn\", \"Walking\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0c464e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.326913Z",
     "iopub.status.busy": "2023-05-26T11:48:30.325725Z",
     "iopub.status.idle": "2023-05-26T11:48:30.336416Z",
     "shell.execute_reply": "2023-05-26T11:48:30.334810Z"
    },
    "papermill": {
     "duration": 0.022252,
     "end_time": "2023-05-26T11:48:30.340016",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.317764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def down_sample_stf(df, n_splits):   \n",
    "    print(f\"before split df has: {df.shape[0]} rows, {df.Subject.nunique()} people\")\n",
    "    n_rows_init = df.shape[0]\n",
    "    n_subjects_init = df.Subject.nunique()\n",
    "    X = df.drop(\"target\", axis = 1)\n",
    "    y = df[\"target\"]\n",
    "    groups = df[\"Subject\"]\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):\n",
    "        train = df.loc[train_index]\n",
    "        valid = df.loc[test_index]\n",
    "        break\n",
    "        \n",
    "    print(f\"after split train has: {train.shape[0]} rows and {train.Subject.nunique()} people\")\n",
    "    print(f\"valid has:{valid.shape[0]} rows and {valid.Subject.nunique()} people\")\n",
    "\n",
    "    return train, valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88540e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.355805Z",
     "iopub.status.busy": "2023-05-26T11:48:30.355283Z",
     "iopub.status.idle": "2023-05-26T11:48:30.362541Z",
     "shell.execute_reply": "2023-05-26T11:48:30.361004Z"
    },
    "papermill": {
     "duration": 0.019159,
     "end_time": "2023-05-26T11:48:30.365796",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.346637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_dtypes(df):\n",
    "    df[\"StartHesitation\"] = df[\"StartHesitation\"].astype(\"bool\")\n",
    "    df[\"Turn\"] = df[\"Turn\"].dfstype(\"bool\")\n",
    "    df[\"Walking\"] = df[\"Walking\"].astype(\"bool\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e2ae9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.380956Z",
     "iopub.status.busy": "2023-05-26T11:48:30.380044Z",
     "iopub.status.idle": "2023-05-26T11:48:30.389145Z",
     "shell.execute_reply": "2023-05-26T11:48:30.387795Z"
    },
    "papermill": {
     "duration": 0.020059,
     "end_time": "2023-05-26T11:48:30.392142",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.372083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_outliers(df):\n",
    "    for col in ['AccV','AccML','AccV']:\n",
    "        max_value = df[col].quantile(q=0.99)\n",
    "        min_value = df[col].quantile(q=0.01)\n",
    "        df[col] = np.where(df[col] > max_value, max_value, df[col])\n",
    "        df[col] = np.where(df[col] < min_value, min_value, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa281d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.407836Z",
     "iopub.status.busy": "2023-05-26T11:48:30.407356Z",
     "iopub.status.idle": "2023-05-26T11:48:30.426165Z",
     "shell.execute_reply": "2023-05-26T11:48:30.424816Z"
    },
    "papermill": {
     "duration": 0.030551,
     "end_time": "2023-05-26T11:48:30.429450",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.398899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
    "            if (col_type != 'object'):\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
    "    \n",
    "    return df\n",
    "#reference: https://www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8726c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.444276Z",
     "iopub.status.busy": "2023-05-26T11:48:30.443812Z",
     "iopub.status.idle": "2023-05-26T11:48:30.459682Z",
     "shell.execute_reply": "2023-05-26T11:48:30.458181Z"
    },
    "papermill": {
     "duration": 0.027044,
     "end_time": "2023-05-26T11:48:30.462814",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.435770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(base,isTest=False, black_list = []):\n",
    "    train= pd.DataFrame()\n",
    "    if \"tdcsfog\" in base:\n",
    "        is_td = True\n",
    "    else:\n",
    "        is_td = False\n",
    "    \n",
    "    for train_path in tqdm(os.listdir(base)):\n",
    "        file_path = base + '/'+train_path\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = flat_outliers(df)\n",
    "        df = FE(df, is_td)\n",
    "        if not isTest:\n",
    "            df = create_target(df)\n",
    "        df[\"file\"] = train_path.split(\".\")[0]\n",
    "        df[\"id\"] = df[\"file\"].astype(\"str\") + \"_\" + df[\"Time\"].astype(\"str\")\n",
    "        \n",
    "        dot_index = train_path.index(\".\")\n",
    "        file_id = train_path[:dot_index]\n",
    "        \n",
    "        if \"tdcsfog\" in base:\n",
    "            df[\"Subject\"] = tdcsfog_subject_dict[file_id]\n",
    "            df[\"Medication\"] =  tdcsfog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = tdcsfog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =tdcsfog_Id_Test[file_id]\n",
    "\n",
    "        else:\n",
    "            df[\"Subject\"] = defog_subject_dict[file_id]\n",
    "            df[\"Medication\"] = defog_medication_dict[file_id]\n",
    "            df[\"Visit\"] = defog_Id_Visit[file_id]\n",
    "            df[\"Test_level\"] =defog_Id_Test[file_id]\n",
    "\n",
    "        if train.shape[0] == 0:\n",
    "            cur_black_list = [c for c in black_list if c in df.columns]\n",
    "        train = train.append(df.drop(cur_black_list, axis = 1))\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "    train = reduce_memory_usage(train)\n",
    "    train.reset_index(drop=True, inplace=True)        \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6e5324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T11:48:30.477121Z",
     "iopub.status.busy": "2023-05-26T11:48:30.476674Z",
     "iopub.status.idle": "2023-05-26T12:25:20.987208Z",
     "shell.execute_reply": "2023-05-26T12:25:20.985760Z"
    },
    "papermill": {
     "duration": 2210.521339,
     "end_time": "2023-05-26T12:25:20.990271",
     "exception": false,
     "start_time": "2023-05-26T11:48:30.468932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/833 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "100%|██████████| 833/833 [34:33<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 5347.98 MB\n",
      "Memory usage became:  2042.9449615478516  MB\n",
      "(7062672, 124)\n",
      "(7062672, 130)\n",
      "0 nans\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdcsfog_train = make_df(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog\", black_list=black_list)\n",
    "print(tdcsfog_train.shape)\n",
    "# merging only on Subject because Visit is relevant for defog only\n",
    "tdcsfog_train = tdcsfog_train.merge(subjects.drop(\"Visit\",axis = 1),\n",
    "                                    on=[\"Subject\"], how=\"left\")\n",
    "print(tdcsfog_train.shape)\n",
    "\n",
    "tdcsfog_train['Sex'] = np.where(tdcsfog_train['Sex'] == \"M\", 1, 0)\n",
    "\n",
    "print(f\"{tdcsfog_train.isna().sum().sum()} nans\")\n",
    "isn = tdcsfog_train.isna().sum()\n",
    "isn[isn > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07879c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:25:21.165023Z",
     "iopub.status.busy": "2023-05-26T12:25:21.164154Z",
     "iopub.status.idle": "2023-05-26T12:26:16.658434Z",
     "shell.execute_reply": "2023-05-26T12:26:16.656911Z"
    },
    "papermill": {
     "duration": 55.667571,
     "end_time": "2023-05-26T12:26:16.743334",
     "exception": false,
     "start_time": "2023-05-26T12:25:21.075763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2413.39 MB\n",
      "Memory usage became:  2103.5643615722656  MB\n",
      "before split df has: 7062672 rows, 62 people\n",
      "after split train has: 4788836 rows and 46 people\n",
      "valid has:2273836 rows and 16 people\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdcsfog_train = reduce_memory_usage(tdcsfog_train)\n",
    "\n",
    "train, valid = down_sample_stf(tdcsfog_train, 4)\n",
    "del tdcsfog_train\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ebd980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T12:26:16.910294Z",
     "iopub.status.busy": "2023-05-26T12:26:16.909814Z",
     "iopub.status.idle": "2023-05-26T12:26:50.183147Z",
     "shell.execute_reply": "2023-05-26T12:26:50.181358Z"
    },
    "papermill": {
     "duration": 33.360825,
     "end_time": "2023-05-26T12:26:50.186799",
     "exception": false,
     "start_time": "2023-05-26T12:26:16.825974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1490.21 MB\n",
      "Memory usage became:  1490.2078323364258  MB\n",
      "Memory usage of dataframe is 871.40 MB\n",
      "Memory usage became:  871.3971786499023  MB\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(reduce_memory_usage(train.reset_index(drop=True)), open(\"train_td.pkl\", \"wb\"))\n",
    "pickle.dump(reduce_memory_usage(valid.reset_index(drop=True)), open(\"valid_td.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2320.424879,
   "end_time": "2023-05-26T12:26:51.608175",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-26T11:48:11.183296",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
